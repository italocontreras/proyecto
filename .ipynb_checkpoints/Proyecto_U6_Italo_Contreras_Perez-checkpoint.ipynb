{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><font color=\"#004D7F\" size=6>Módulo 6. Fase de optimización y forecasting</font></h2>\n",
    "\n",
    "\n",
    "\n",
    "<h1><font color=\"#004D7F\" size=5>1. Pipelines</font></h1>\n",
    "\n",
    "<br><br>\n",
    "<div style=\"text-align: right\">\n",
    "<font color=\"#004D7F\" size=3>Manuel Castillo-Cara</font><br>\n",
    "<font color=\"#004D7F\" size=3>Machine Learning con Python</font><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h2><font color=\"#004D7F\" size=5>Índice</font></h2>\n",
    "<a id=\"indice\"></a>\n",
    "\n",
    "* [1. Introducción](#section1)\n",
    "    * [1.1. Librerías](#section11)\n",
    "    * [1.2. CSV](#section12)\n",
    "* [2. `Pipeline`](#section2)\n",
    "* [3. `FeatureUnion`](#section3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{ width:98% }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Permite ajustar la anchura de la parte útil de la libreta (reduce los márgenes)\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container{ width:98% }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section1\"></a>\n",
    "# <font color=\"#004D7F\"> 1. Introducción</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un Pipeline consiste en una combinación de estimadores que se ejecutan como si fuesen uno. Más concretamente se trata de una secuencia de transformaciones y el último es un estimador de cualquier tipo (transformador, clasificador, etc.). \n",
    "\n",
    "Pipeline se encarga de ir llamando a las funciones `fit` y `transform` de cada uno de los transformadores hasta que llega al último de ellos, siendo la entrada de la función `fit` el resultado del `transform` anterior. Pipeline tendrá aquellas funciones correspondientes a su último estimador, es decir, si al final hay un clasificador, el Pipeline tendrá las funciones `fit`, `predict` y `score`, si es un transformador, `fit` y `transform`. Se trata de una herramienta muy útil que permite reducir el tamaño del código y ayuda a la reproducibilidad de diferentes experimentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 1.1. Cargando mi dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voy a seguir usando el dataset que escogi desde un prinicipio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     X  Y  FFMC    DMC     DC   ISI  temp  RH  wind  rain\n",
       "0    7  5  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0\n",
       "1    7  4  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0\n",
       "2    7  4  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0\n",
       "3    8  6  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2\n",
       "4    8  6  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0\n",
       "..  .. ..   ...    ...    ...   ...   ...  ..   ...   ...\n",
       "512  4  3  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0\n",
       "513  2  4  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0\n",
       "514  7  4  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0\n",
       "515  1  4  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0\n",
       "516  6  3  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0\n",
       "\n",
       "[517 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "filename_reg = 'data/forestfires.csv'\n",
    "data = pd.read_csv(filename_reg)\n",
    "data1=data.drop(['month'], axis=1)\n",
    "data2=data1.drop(['day'], axis=1)\n",
    "#names=['X','Y','FFMC','DMC','DC','ISI','temp','RH','wind','rain','area']\n",
    "array_reg = data2.values\n",
    "#Dividamos la data de esta forma par el SuperLerner\n",
    "X=array_reg[:,0:10]\n",
    "Y=array_reg[:,10]\n",
    "X_2=data2.drop(\"area\",1)\n",
    "Y_2=data2[\"area\"]\n",
    "X_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section2\"></a>\n",
    "# <font color=\"#004D7F\"> 2. `Pipeline`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El pipeline se define con dos pasos:\n",
    "1. Estandarizar los datos.\n",
    "2. Aprender un modelo LDA.\n",
    "\n",
    "Observe cómo creamos una lista de pasos de Python que se proporcionan a Pipeline para procesar los datos. Observe también cómo el Pipeline en sí misma se trata como un estimador y se evalúa en su totalidad mediante el procedimiento de validación cruzada _k-fold_. Ejecutar el ejemplo proporciona un resumen del Accuracy de la configuración en el conjunto de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.35% (5.16%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manwest/Documentos/Jupyter/enviroment/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that standardizes the data then creates a model\n",
    "from s kl e a r n . m odel _ sele c ti on import KFold\n",
    "3 > from s kl e a r n . m odel _ sele c ti on import c r o s s _ v al _ s c o r e\n",
    "4 > from s kl e a r n . p rep r o ce s sin g import S t and a rd S c ale r\n",
    "5 > from s kl e a r n . pi p eli n e import Pi p eli n e\n",
    "6 > from s kl e a r n . di s c rimi n a n t _ a n al y si s import Line a rDi s c rimin an tAn al y si s\n",
    "\n",
    "# create pipeline\n",
    "e s tim a t o r s = [ ]\n",
    "9 > e s tim a t o r s . append ( ( ’ s t and a rdi ze ’ , S t and a rd S c ale r ( ) ) )\n",
    "10 > e s tim a t o r s . append ( ( ’ ld a ’ , Line a rDi s c rimin an tAn al y si s ( ) ) )\n",
    "11 > model = Pi p eli n e ( e s tim a t o r s )\n",
    "# evaluate pipeline\n",
    "k f old = KFold ( n _ s p l i t s =10 , random_s ta te =7 )\n",
    " r e s u l t s = c r o s s _ v al _ s c o r e ( model , X , Y , cv=k f old )\n",
    "    p ri n t ( f \" Accuracy : { r e s u l t s . mean ( ) ∗ 1 0 0 . 0 : , . 2 f} %\n",
    "16 ( { r e s u l t s . s td ( ) ∗ 1 0 0 . 0 : , . 2 f } %)\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <font size=5>\n",
    "    <a href=\"#indice\"><i class=\"fa fa-arrow-circle-up\" aria-hidden=\"true\" style=\"color:#004D7F\"></i></a>\n",
    "</font></div>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section3\"></a>\n",
    "# <font color=\"#004D7F\"> 3. `FeatureUnion`</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Pipeline proporciona una herramienta práctica llamada `FeatureUnion` que permite combinar los resultados de múltiples procedimientos de selección y extracción de características en un conjunto de datos más grande en el que se puede entrenar un modelo. Es importante destacar que toda la extracción de características y la unión de características se produce dentro de cada _fold_ del procedimiento de validación cruzada. El siguiente ejemplo muestra el Pipeline definida con cuatro pasos:\n",
    "1. Extracción de características con PCA (3 características). \n",
    "2. Extracción de características con selección estadística (6 características).\n",
    "3. Unión de características.\n",
    "4. Evaluación con un modelo LoR.\n",
    "\n",
    "Observe cómo `FeatureUnion` es un Pipeline propio que, a su vez, es un solo paso en el Pipeline final utilizado para alimentar a LoR; en resumidas cuentas \"es un Pipeline dentro de otro\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/manwest/Documentos/Jupyter/enviroment/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 77.60% (5.16%)\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline that extracts features from the data then creates a model\n",
    "from s kl e a r n . m odel _ sele c ti on import KFold\n",
    "3 > from s kl e a r n . m odel _ sele c ti on import c r o s s _ v al _ s c o r e\n",
    "4 > from s kl e a r n . pi p eli n e import Pi p eli n e\n",
    "5 > from s kl e a r n . pi p eli n e import Fea tureUnion\n",
    "6 > from s kl e a r n . line a r _model import L o gi s ti cR e g r e s si o n\n",
    "7 > from s kl e a r n . f e a t u r e _ s e l e c t i o n import S el e c t K B e s t\n",
    "\n",
    "\n",
    "# create feature union\n",
    "f e a t u r e s = [ ]\n",
    "10 > f e a t u r e s . append ( ( ’ pca ’ , PCA( n_components =3 ) ) )\n",
    "11 > f e a t u r e s . append ( ( ’ s e l e c t _ b e s t ’ , S el e c t K B e s t ( k=6 ) ) )\n",
    "12 > fe a tu re _uni on = Fea tureUnion ( f e a t u r e s )\n",
    "\n",
    "# create pipeline\n",
    "e s tim a t o r s = [ ]\n",
    "15 > e s tim a t o r s . append ( ( ’ fe a tu re _uni on ’ , fe a tu re _uni on ) )\n",
    "16 > e s tim a t o r s . append ( ( ’ l o g i s t i c ’ , L o gi s ti cR e g r e s si o n ( s ol v e r = ’ l b f g s ’ ,\n",
    "17 m ax _i te r =1000 ) ) )\n",
    " model = Pi p eli n e ( e s tim a t o r s )\n",
    "    \n",
    "# evaluate pipeline\n",
    " k f old = KFold ( n _ s p l i t s =10 , random_s ta te =7 )\n",
    "21 > r e s u l t s = c r o s s _ v al _ s c o r e ( model , X , Y , cv=k f old )\n",
    "22 > p ri n t ( f \" Accuracy : { r e s u l t s . mean ( ) ∗ 1 0 0 . 0 : , . 2 f} %\n",
    "23 ( { r e s u l t s . s td ( ) ∗ 1 0 0 . 0 : , . 2 f } %)\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section4\"></a>\n",
    "# <font color=\"#004D7F\"> 4. Procesamiento de datos avanzado</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 4.1. Valores de datos perdidos</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando tenemos valores Nan se debe tratarlos, la media si tengo valores continuos y la moda si tengo valores discretos. Por ejemplo si tengo 300 instancias en mi modelo y de esos hay 150 valores NaN para cierta caracteristica no podemos ponerle la media porque estariamos haciendo un overfiting tremendo, lo que deberiamos hacer es eliminar esa caracteristica. La imputacion se hace cuando se tiene un maximo del 20% de valores NaN de nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X       0\n",
      "Y       0\n",
      "FFMC    0\n",
      "DMC     0\n",
      "DC      0\n",
      "ISI     0\n",
      "temp    0\n",
      "RH      0\n",
      "wind    0\n",
      "rain    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(np.sum(np.isnan(X_2)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que no hay valores Nan, aun asi intentaremos hacer el simple Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021639831514046137\n"
     ]
    }
   ],
   "source": [
    "# creamos un o b j e t o Imputer con l o s p a r m e t r o s por d e f e c t o\n",
    "imp = SimpleImputer ( )\n",
    "# creamos una nueva base de da tos si n v al o r e s perdidos\n",
    "X_2_trans = imp.fit_transform(X_2)\n",
    "\n",
    "# creamos un o b j e t o con l o s parame tros por d e f e c t o\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_2_trans,Y_2)\n",
    "X_2_prediction = lr.predict(X_2_trans)\n",
    "#print('Accuracy del L o gi s ti cR e g r e s si o n s c o re'’ )\n",
    "print(lr.score(X_2_trans,Y_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 4.2. Escalar atributo clase</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora usaremos un SimpleImputer con un Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de acierto:0.021639831514046137\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.pipeline import Pipeline \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "pipe = Pipeline ([('Imp',SimpleImputer()) , \n",
    "                  ('LiR',LinearRegression())]) \n",
    "pipe . fit (X , Y ) \n",
    "print (f\"Tasa de acierto:{pipe.score (X,Y)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que de esta forma nos sale la misma tasa de acierto que cuando no usamos un Pipeline, vemos que tb se puede usar el score en vez de la validacion cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 4.3. Escalar atributo clase</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mejor dicho escalar el atributo 'target', porque cuando hablamos de escalar el atributo target es proque nos estamos refiriendo a un problema de regresion, es decir es del tipo numerico y le aplicamos una normalizacion o una estandarizacion; esto a veces es muy bueno aplicarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 12.988 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn . model_selection import cross_val_score \n",
    "from sklearn . model_selection import KFold \n",
    "from sklearn . pipeline import Pipeline \n",
    "from sklearn . linear_model import HuberRegressor \n",
    "from sklearn . preprocessing import MinMaxScaler \n",
    "from sklearn .compose import TransformedTargetRegressor \n",
    "\n",
    "# prepare the model with input scaling \n",
    "pipeline = Pipeline ( steps =[( 'normalize' , MinMaxScaler() ) , ( 'model' , HuberRegressor () ) ]) \n",
    "\n",
    "# prepare the model with target scaling\n",
    "model = TransformedTargetRegressor( regressor=pipeline , transformer=MinMaxScaler() ) \n",
    "\n",
    "# evaluate model \n",
    "cv = KFold( n_splits=10, shuffle=True , random_state=1) \n",
    "scores = cross_val_score (model, X, Y, scoring='neg_mean_absolute_error', cv=cv) \n",
    "\n",
    "# convert scores to positive \n",
    "scores = np. absolute ( scores ) \n",
    "# summarize the result \n",
    "s_mean = np.mean( scores ) \n",
    "print ( 'Mean MAE: %.3f ' % (s_mean) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que al aplicar una transformacion al target se obtiene un error mucho menor comparado a otros ejercicios anteriores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver si al aplicar un Yeo-Jhonson obtenemos mejores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MAE: 12.840 \n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn . model_selection import cross_val_score \n",
    "from sklearn . model_selection import KFold \n",
    "from sklearn . pipeline import Pipeline \n",
    "from sklearn . linear_model import HuberRegressor \n",
    "from sklearn .compose import TransformedTargetRegressor \n",
    "from sklearn . preprocessing import PowerTransformer \n",
    "import pandas as pd \n",
    "    \n",
    "# prepare the model with input scaling \n",
    "pipeline = Pipeline ( steps =[( 'power' , PowerTransformer () ) ,  ( 'model' , HuberRegressor () ) ]) \n",
    "\n",
    "# prepare the model with target scaling \n",
    "model = TransformedTargetRegressor( regressor=pipeline , transformer=PowerTransformer () ) \n",
    "\n",
    "# evaluate model \n",
    "cv = KFold( n_splits=10, shuffle=True , random_state=1) \n",
    "scores = cross_val_score (model, X, Y, scoring='neg_mean_absolute_error', cv=cv) \n",
    "\n",
    "# convert scores to positive \n",
    "scores = np. absolute ( scores ) \n",
    "\n",
    "# summarize the result \n",
    "s_mean = np.mean( scores ) \n",
    "print ( 'Mean MAE: %.3f ' % (s_mean) )\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section12\"></a>\n",
    "## <font color=\"#004D7F\"> 4.4. One Hot Encoding</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section5\"></a>\n",
    "# <font color=\"#004D7F\"> 5. Fase de Optimizacion</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que ya se tiene el modelo decidido lo que haremos es buscar como hacer como darle un ultimo ajusto de tuercas y comprobar con que hiperparametros me funciona mejor el algoritmo. Hay 2 tecnicas principales para bu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section51\"></a>\n",
    "## <font color=\"#004D7F\"> 5.1. Grid Search</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search for Algorithm Tuning \n",
    "2 > import numpy as np \n",
    "3 > from sklearn .svm import SVC \n",
    "4 > from sklearn . model_selection import GridSearchCV \n",
    "5 > Grid search params \n",
    "6 > c = np. array ([1.0 , 2.0 , 3.0 , 4.0 , 5.0 , 6.0]) \n",
    "7 > param_grid = dict (C = c) \n",
    "8 > model = SVC() \n",
    "9 > grid = GridSearchCV( estimator=model, param_grid=param_grid , cv=5) \n",
    "10 > grid . fit (X, Y) \n",
    "11 > print ( f \"Accuracy optimo: {grid . best_score_ .mean() ∗100.0: ,.2 f}%\" ) \n",
    "12 > print ( f \"Valor de C optimo: {grid . best_estimator_ .C} \" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section52\"></a>\n",
    "## <font color=\"#004D7F\"> 5.2. Random Search</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from sklearn .svm import SVC \n",
    "from sklearn . model_selection import RandomizedSearchCV \n",
    "Random search params \n",
    "param_random = { ’C’ : uniform(1 , 50) } \n",
    "model = SVC() \n",
    "rsearch = RandomizedSearchCV( estimator=model, param_distributions=param_grid , n_iter=50, random_state=7, cv=5) \n",
    "rsearch . fit (X, Y) \n",
    "print ( f \"Accuracy optimo :{ rsearch . best_score_ .mean() ∗100.0: ,.2 f}%\" ) \n",
    "print ( f \"Valor de C optimo: { rsearch . best_estimator_ .C} \" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"section6\"></a>\n",
    "# <font color=\"#004D7F\"> 6. Fase de Forecasting</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiene la tarea principal de hacer predicciones con datos que no esten etiquetados, nuestra algoritmo indicara el nuevo target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section61\"></a>\n",
    "## <font color=\"#004D7F\"> 6.1. Pickle</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section61\"></a>\n",
    "## <font color=\"#004D7F\"> 6.1. Pickle</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
