{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Importamos las librerias"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# Classification Project: Sonar rocks or mines\n\n# Load libraries\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n# Load sklearn\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.metrics import mean_squared_error\n\n\nimport warnings\nwarnings.filterwarnings('ignore')",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/home/nbuser/anaconda3_501/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n  return f(*args, **kwds)\n/home/nbuser/anaconda3_501/lib/python3.6/site-packages/matplotlib/font_manager.py:229: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  'Matplotlib is building the font cache using fc-list. '\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Cargamos el dataset"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "filename_reg = 'forestfires.csv'\ndata = pd.read_csv(filename_reg)\ndata1=data.drop(['month'], axis=1)\ndata2=data1.drop(['day'], axis=1)\n#names=['X','Y','FFMC','DMC','DC','ISI','temp','RH','wind','rain','area']\n\n#Dividamos la data \n\narray_reg = data2.values\n\nX=array_reg[:,0:10]\nY=array_reg[:,10]\n\nX_2=data2.drop(\"area\",1)\nY_2=data2[\"area\"]",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Creamos conjunto de validacion"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "validation_size = 0.20\nseed = 7\nX_train, X_validation, Y_train, Y_validation = train_test_split(X, Y, \n                                               test_size=validation_size, random_state=seed)\n\n",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Creando un arreglo con modelos ensamblados"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "num_folds = 10\nscoring = 'neg_mean_squared_error'\n\nnum_trees = 100 \nmax_features=3\n\n\nmodels= []\n\nmodels.append(( 'RandomForest',RandomForestRegressor( n_estimators=num_trees ,max_features=max_features, random_state=seed)))\nmodels.append(( 'ExtraTree',ExtraTreesRegressor( n_estimators=num_trees ,max_features=max_features, random_state=seed)))\nmodels.append(( 'Adaboost',AdaBoostRegressor( n_estimators=num_trees, random_state=seed)))\nmodels.append(( 'Gradient',GradientBoostingRegressor( n_estimators=num_trees, random_state=seed)))\n\nresults = []\nnames = []\nfor name, model in models:\n    kfold = KFold(n_splits=num_folds, random_state=seed)\n    cv_results = cross_val_score(model, X_train, Y_train, cv=kfold, scoring=scoring)\n    results.append(cv_results)\n    names.append(name)\n    print({name}, cv_results.mean(), ({cv_results.std()}))",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'RandomForest'} -5200.137208715254 {8404.66890308882}\n{'ExtraTree'} -5370.550162221005 {8608.633974086057}\n{'Adaboost'} -5368.309143912347 {8498.933083618847}\n{'Gradient'} -6869.227656316289 {9059.800922398877}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Ahora vemos el Adaboost por si solo"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "kfold = KFold( n_splits=10, random_state=seed) \nmodel = AdaBoostRegressor( n_estimators=num_trees, random_state=seed) \nresults = cross_val_score (model, X_train, Y_train, cv=kfold) \nprint({\"Adaboost\"}, {results.mean()}, ({ results.std()}))  ",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": "{'Adaboost'} {-3.87826758317958} {8.4137820540476}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Observamos que el resultado es muy diferente al Adaboost en el arreglo de modelos"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}